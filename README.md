# clutch.io_webscraping

Here's an outline of the steps we'll follow:

Download the webpage using requests
Parse the HTML source code using beautiful soup
Extract the required information and URLs from page
Compile extracted information into Python lists and dictionaries
Extract and combine data from multiple pages
Save the extracted information to a CSV file.

Steps to install BeautifulSoup
1) Open cmd 
2) Type in "pip install bs4"                        #this install the beautifulsoup library
3) Type in "pip install requests"                   #this allows the code to send requests to access the library.

Requirements
1) beautifulsoup4==4.10.0
2) charset-normalizer==2.0.5
3) html5lib==1.1
4) idna==3.2
5) requests==2.26.0
6) six==1.16.0
7) soupsieve==2.2.1
8) urllib3==1.26.6
9) webencodings==0.5.1

Environment Configurations
1) open cmd
2) create virtual environment by typing "python -m venv venv"
3) run the virtual environment by typing ".\env\Scripts\activate"

To run the scraper
1) open cmd
2) open the folder where the project is saved in cmd
3) enter the command "python
